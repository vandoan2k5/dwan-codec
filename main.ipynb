{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Lumina\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "config = Namespace(\n",
    "    in_channel=1,          # Code m·∫∑c ƒë·ªãnh l√† 1 (Mono)\n",
    "    channel=512,           # Code m·∫∑c ƒë·ªãnh l√† 512 (L∆∞u √Ω: code c≈© c·ªßa b·∫°n l√† 128, h√£y check l·∫°i file config g·ªëc n·∫øu size model qu√° l·ªõn)\n",
    "    n_res_block=2,         # (Gi·ªØ nguy√™n ho·∫∑c ch·ªânh theo config l√∫c train)\n",
    "    n_res_channel=32,      # (Gi·ªØ nguy√™n ho·∫∑c ch·ªânh theo config l√∫c train)\n",
    "    quantizer=\"fsq\",       # B·∫Øt bu·ªôc c√≥ ƒë·ªÉ tr√°nh l·ªói AttributeError\n",
    "    levels=[7, 5, 5, 5, 5],# M·∫∑c ƒë·ªãnh trong code c·ªßa b·∫°n. T√≠ch = 4375\n",
    "    embed_dim=5,           \n",
    "    \n",
    "    n_embed=4375,          # 7*5*5*5*5 = 4375\n",
    "    decay=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f89acbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: checkpoints/audio_fsq-n_embed-4375/ckpts/epoch_195.pt\n",
      "Successfully loaded state dict!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoints/audio_fsq-n_embed-4375/ckpts/epoch_195.pt\" # ƒê∆∞·ªùng d·∫´n file checkpoint c·ªßa b·∫°n\n",
    "input_audio_path = \"/kaggle/lumina/assets/en_00002.wav\"    # File √¢m thanh g·ªëc mu·ªën test\n",
    "output_audio_path = input_audio_path[:-4]+\"_re.wav\" # File √¢m thanh sau khi t√°i t·∫°o\n",
    "\n",
    "target_sample_rate = 24000  \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "lumina = Lumina(\n",
    "    config=config, \n",
    "    checkpoint_path=checkpoint_path, \n",
    "    sample_rate=target_sample_rate, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa51c1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîä ƒêang gi·∫£i m√£ tokens ng∆∞·ª£c l·∫°i th√†nh audio...\n",
      "‚úÖ ƒê√£ l∆∞u file t√°i t·∫°o t·∫°i: /kaggle/lumina/assets/en_00002_re.wav\n",
      "   - Shape output wav: torch.Size([1, 228352])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "tokens = lumina.encode(input_audio_path)\n",
    "print(f\"\\nüîä ƒêang gi·∫£i m√£ tokens ng∆∞·ª£c l·∫°i th√†nh audio...\")\n",
    "\n",
    "recon_wav, sr = lumina.decode(tokens)\n",
    "\n",
    "if recon_wav.dim() == 1:\n",
    "    recon_wav = recon_wav.unsqueeze(0)\n",
    "    \n",
    "torchaudio.save(output_audio_path, recon_wav, sr)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u file t√°i t·∫°o t·∫°i: {output_audio_path}\")\n",
    "print(f\"   - Shape output wav: {recon_wav.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059dd07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumina (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
